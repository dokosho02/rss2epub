{
    "bozo": false,
    "entries": [
        {
            "title": "Constrained non-linear AVO inversion based on the adjoint-state optimization",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Constrained non-linear AVO inversion based on the adjoint-state optimization"
            },
            "summary": "<p><span><big>Constrained non-linear AVO inversion based on the adjoint-state optimization</big></span><br /></p><p><span><small><i>Nisar Ahmed, Wiktor Waldemar Weibull, Dario Grana</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105214</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Pre-stack AVO inversion of seismic data is a modeling tool for estimating subsurface elastic properties. Our focus is on the model-based inversion method where then unknown variables are estimated by minimizing the misfit to the observed data. Standard approaches for non-linear AVO inversion are based on the gradient descent optimization algorithms that require the calculation of the gradient equations of the objective function. To improve the accuracy and efficiency of these methods, we developed a technique that uses an implementation of the adjoint-state-based gradient computation. The inversion algorithm relies on three basic modeling components consisting of a convolution-based forward model using a linearized approximation of the Zoeppritz equation, the definition of the objective function, and the adjoint-computed gradient. To achieve an accurate solution, we choose a second-order optimization algorithm known as the Limited memory-BFGS (L-BFGS) that implicitly approximates the inverse Hessian matrix. This approach is more efficient than traditional optimization methods. The main novelty of the proposed approach is the derivation of the adjoint-state equations for the gradient of the objective function. The application of the proposed method is demonstrated using 1D and 2D synthetic datasets based on data from the Edvard Grieg oil field. The seismic data for these applications is generated by using both convolutional modeling and finite difference methods. The results of the proposed method are accurate and the computational approach is efficient. The results show that the algorithm reliably retrieves the elastic variables, P- and S-wave velocities and density for both convolutional and finite difference models.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Constrained non-linear AVO inversion based on the adjoint-state optimization</big></span><br /></p><p><span><small><i>Nisar Ahmed, Wiktor Waldemar Weibull, Dario Grana</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105214</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Pre-stack AVO inversion of seismic data is a modeling tool for estimating subsurface elastic properties. Our focus is on the model-based inversion method where then unknown variables are estimated by minimizing the misfit to the observed data. Standard approaches for non-linear AVO inversion are based on the gradient descent optimization algorithms that require the calculation of the gradient equations of the objective function. To improve the accuracy and efficiency of these methods, we developed a technique that uses an implementation of the adjoint-state-based gradient computation. The inversion algorithm relies on three basic modeling components consisting of a convolution-based forward model using a linearized approximation of the Zoeppritz equation, the definition of the objective function, and the adjoint-computed gradient. To achieve an accurate solution, we choose a second-order optimization algorithm known as the Limited memory-BFGS (L-BFGS) that implicitly approximates the inverse Hessian matrix. This approach is more efficient than traditional optimization methods. The main novelty of the proposed approach is the derivation of the adjoint-state equations for the gradient of the objective function. The application of the proposed method is demonstrated using 1D and 2D synthetic datasets based on data from the Edvard Grieg oil field. The seismic data for these applications is generated by using both convolutional modeling and finite difference methods. The results of the proposed method are accurate and the computational approach is efficient. The results show that the algorithm reliably retrieves the elastic variables, P- and S-wave velocities and density for both convolutional and finite difference models.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001637",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001637"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001637"
        },
        {
            "title": "Multi-mineral segmentation of micro-tomographic images using a convolutional neural network",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Multi-mineral segmentation of micro-tomographic images using a convolutional neural network"
            },
            "summary": "<p><span><big>Multi-mineral segmentation of micro-tomographic images using a convolutional neural network</big></span><br /></p><p><span><small><i>Jiabin Liang, Yongyang Sun, Maxim Lebedev, Boris Gurevich, ... Stanislav Glubokovskikh</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105217</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Micro X-ray-Computed Tomographic (micro-CT) images are often used for calibration of interpretation models that relate physical rock properties to the rock microstructure. Some computed properties, for example, permeability, may be relatively insensitive to the mineral composition of the rock matrix, while electrical conductivity and stiffness show strong dependence on the volume fractions and spatial distribution of minerals. This information could potentially be extracted from X-ray density of these images through a procedure commonly called segmentation. However, the range of X-ray density overlaps for different minerals, hence an effective segmentation workflow need to consider both the density values and shapes of the minerals. Such image processing workflows consist of many stages, and thus become time and computationally expensive and involve a lot of manual labor. This paper proposes an automated workflow for the multi-mineral segmentation of micro X-ray-Computed Tomographic (micro-CT) images using a convolutional neural network (CNN). The CNN model is trained using labels of two sets of images of a Bentheimer sandstone that are segmented into pore, quartz, clay and feldspar using a sophisticated interactive workflow. The trained model is then used to segment a new set of images of the Bentheimer sandstone. The segmented multi-mineral labels can achieve an accuracy of \u223c97% and the process takes only \u223c10&nbsp;min as compared with interactive workflow which takes \u223c3&nbsp;h. Although, CNN-based segmentation algorithms were published in the literature before, the proposed model is capable of more sophisticated segmentation and achieves superior accuracy on a completely blind test set. Potentially, our approach might generalize well to other lithology for the micro-CT image analysis.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Multi-mineral segmentation of micro-tomographic images using a convolutional neural network</big></span><br /></p><p><span><small><i>Jiabin Liang, Yongyang Sun, Maxim Lebedev, Boris Gurevich, ... Stanislav Glubokovskikh</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105217</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Micro X-ray-Computed Tomographic (micro-CT) images are often used for calibration of interpretation models that relate physical rock properties to the rock microstructure. Some computed properties, for example, permeability, may be relatively insensitive to the mineral composition of the rock matrix, while electrical conductivity and stiffness show strong dependence on the volume fractions and spatial distribution of minerals. This information could potentially be extracted from X-ray density of these images through a procedure commonly called segmentation. However, the range of X-ray density overlaps for different minerals, hence an effective segmentation workflow need to consider both the density values and shapes of the minerals. Such image processing workflows consist of many stages, and thus become time and computationally expensive and involve a lot of manual labor. This paper proposes an automated workflow for the multi-mineral segmentation of micro X-ray-Computed Tomographic (micro-CT) images using a convolutional neural network (CNN). The CNN model is trained using labels of two sets of images of a Bentheimer sandstone that are segmented into pore, quartz, clay and feldspar using a sophisticated interactive workflow. The trained model is then used to segment a new set of images of the Bentheimer sandstone. The segmented multi-mineral labels can achieve an accuracy of \u223c97% and the process takes only \u223c10&nbsp;min as compared with interactive workflow which takes \u223c3&nbsp;h. Although, CNN-based segmentation algorithms were published in the literature before, the proposed model is capable of more sophisticated segmentation and achieves superior accuracy on a completely blind test set. Potentially, our approach might generalize well to other lithology for the micro-CT image analysis.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001662",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001662"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001662"
        },
        {
            "title": "Paw-Net: Stacking ensemble deep learning for segmenting scanning electron microscopy images of fine-grained shale samples",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Paw-Net: Stacking ensemble deep learning for segmenting scanning electron microscopy images of fine-grained shale samples"
            },
            "summary": "<p><span><big>Paw-Net: Stacking ensemble deep learning for segmenting scanning electron microscopy images of fine-grained shale samples</big></span><br /></p><p><span><small><i>Binqian Yin, Qinhong Hu, Yingying Zhu, Chen Zhao, Keren Zhou</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105218</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Segmentation of scanning electron microscopy (SEM) images is critical yet time-consuming for geological analyses, as it needs to differentiate the boundaries for different mineral objects to facilitate subsequent analyses, such as porosity calculation. Recently, various machine learning methods, especially convolutional neural networks (CNNs), have been explored to segment SEM images of fine-grained shale samples. However, we found that general CNNs do not yield optimal performance due to insufficient training data and imbalanced objects in SEM images. This work has revised the U-Net architecture, a popular approach for biomedical image analyses, by incorporating a loss function that addresses the imbalance issue. Furthermore, we used the ensemble learning method to train multiple models and combined the results to improve the overall performance of segmentation. We prepared 2162 sub-images from raw SEM images in our experiments and divided them into training, validation, and testing datasets. The overall results show that our method improves the average Intersection over Union (IOU) of mineral objects from 0.49 to 0.58, compared to the original U-Net model. Our method can clearly distinguish each object from others with boundaries, even in highly imbalanced images. Training our models takes less than 3&nbsp;mins using a single GPU, while manual labeling can take up to 3&nbsp;hrs for each image. Therefore, the method helps geoscientists gain insights quickly and effectively by building neural network models from a small dataset of SEM images.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Paw-Net: Stacking ensemble deep learning for segmenting scanning electron microscopy images of fine-grained shale samples</big></span><br /></p><p><span><small><i>Binqian Yin, Qinhong Hu, Yingying Zhu, Chen Zhao, Keren Zhou</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105218</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Segmentation of scanning electron microscopy (SEM) images is critical yet time-consuming for geological analyses, as it needs to differentiate the boundaries for different mineral objects to facilitate subsequent analyses, such as porosity calculation. Recently, various machine learning methods, especially convolutional neural networks (CNNs), have been explored to segment SEM images of fine-grained shale samples. However, we found that general CNNs do not yield optimal performance due to insufficient training data and imbalanced objects in SEM images. This work has revised the U-Net architecture, a popular approach for biomedical image analyses, by incorporating a loss function that addresses the imbalance issue. Furthermore, we used the ensemble learning method to train multiple models and combined the results to improve the overall performance of segmentation. We prepared 2162 sub-images from raw SEM images in our experiments and divided them into training, validation, and testing datasets. The overall results show that our method improves the average Intersection over Union (IOU) of mineral objects from 0.49 to 0.58, compared to the original U-Net model. Our method can clearly distinguish each object from others with boundaries, even in highly imbalanced images. Training our models takes less than 3&nbsp;mins using a single GPU, while manual labeling can take up to 3&nbsp;hrs for each image. Therefore, the method helps geoscientists gain insights quickly and effectively by building neural network models from a small dataset of SEM images.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001674",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001674"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001674"
        },
        {
            "title": "Daily Ten-ST-GEE: An open access and fully automated 10-m LST downscaling system",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Daily Ten-ST-GEE: An open access and fully automated 10-m LST downscaling system"
            },
            "summary": "<p><span><big>Daily Ten-ST-GEE: An open access and fully automated 10-m LST downscaling system</big></span><br /></p><p><span><small><i>Mario Mhawej, Yaser Abunnasr</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105220</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>In remote sensing applications, data fusion is a combination of satellite images from different sources, aimed to improve the spatial and/or temporal resolution of the final output. This process also named spatial sharpening or spatial downscaling is required in several Land Surface Temperature-based (LST) studies, ranging from water table estimations and urban heating assessments to volcano activity monitoring. In this study, we propose a Google Earth Engine-based (GEE) daily 10-m LST retrieval system, named daily Ten-ST-GEE. It combines both MODIS and Sentinel-2 satellite products and uses the robust least squares statistical approach for data fusion. We validate the daily Ten-ST-GEE against two airborne TIR images over the Hat Creek region, in California, USA with a MAE of 2.27&nbsp;\u00b0C. The cross-evaluation over the 1-km MODIS LST and the inter-comparison to the 30-m L8 LST in six different sites across the globe showed very promising results (i.e., average MAE less than 1&nbsp;\u00b0C). As the daily Ten-ST-GEE is fully-automated, open-source, user-friendly and freely-accessible, it can be portable to other regions with diverse climatic regimes. This would greatly improve the downscaling initiatives and provide the scientific community with much-needed downscaled LST information.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Daily Ten-ST-GEE: An open access and fully automated 10-m LST downscaling system</big></span><br /></p><p><span><small><i>Mario Mhawej, Yaser Abunnasr</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105220</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>In remote sensing applications, data fusion is a combination of satellite images from different sources, aimed to improve the spatial and/or temporal resolution of the final output. This process also named spatial sharpening or spatial downscaling is required in several Land Surface Temperature-based (LST) studies, ranging from water table estimations and urban heating assessments to volcano activity monitoring. In this study, we propose a Google Earth Engine-based (GEE) daily 10-m LST retrieval system, named daily Ten-ST-GEE. It combines both MODIS and Sentinel-2 satellite products and uses the robust least squares statistical approach for data fusion. We validate the daily Ten-ST-GEE against two airborne TIR images over the Hat Creek region, in California, USA with a MAE of 2.27&nbsp;\u00b0C. The cross-evaluation over the 1-km MODIS LST and the inter-comparison to the 30-m L8 LST in six different sites across the globe showed very promising results (i.e., average MAE less than 1&nbsp;\u00b0C). As the daily Ten-ST-GEE is fully-automated, open-source, user-friendly and freely-accessible, it can be portable to other regions with diverse climatic regimes. This would greatly improve the downscaling initiatives and provide the scientific community with much-needed downscaled LST information.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001698",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001698"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001698"
        },
        {
            "title": "Semantic segmentation of explosive volcanic plumes through deep learning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Semantic segmentation of explosive volcanic plumes through deep learning"
            },
            "summary": "<p><span><big>Semantic segmentation of explosive volcanic plumes through deep learning</big></span><br /></p><p><span><small><i>T.C. Wilkes, T.D. Pering, A.J.S. McGonigle</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105216</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Tracking explosive volcanic phenomena can provide important information for hazard monitoring and volcano research. Perhaps the simplest forms of monitoring instruments are visible-wavelength cameras, which are routinely deployed on volcanoes around the globe. Here, we present the development of deep learning models, based on convolutional neural networks (CNNs), to perform semantic segmentation of explosive volcanic plumes on visible imagery, therefore classifying each pixel of an image as either explosive plume or not explosive plume. We have developed 3 models, each with average validation accuracies of &gt;97% under 10-fold cross-validation; although we do highlight that, due to the limited training and validation dataset, this value is likely an overestimate of real-world performance. We then present model deployment for automated retrieval of plume height, rise speed and propagation direction, all parameters which can have great utility particularly in ash dispersion modelling and associated aviation hazard identification. The 3 trained models are freely available for download at https://doi.org/10.15131/shef.data.17061509.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Semantic segmentation of explosive volcanic plumes through deep learning</big></span><br /></p><p><span><small><i>T.C. Wilkes, T.D. Pering, A.J.S. McGonigle</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105216</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Tracking explosive volcanic phenomena can provide important information for hazard monitoring and volcano research. Perhaps the simplest forms of monitoring instruments are visible-wavelength cameras, which are routinely deployed on volcanoes around the globe. Here, we present the development of deep learning models, based on convolutional neural networks (CNNs), to perform semantic segmentation of explosive volcanic plumes on visible imagery, therefore classifying each pixel of an image as either explosive plume or not explosive plume. We have developed 3 models, each with average validation accuracies of &gt;97% under 10-fold cross-validation; although we do highlight that, due to the limited training and validation dataset, this value is likely an overestimate of real-world performance. We then present model deployment for automated retrieval of plume height, rise speed and propagation direction, all parameters which can have great utility particularly in ash dispersion modelling and associated aviation hazard identification. The 3 trained models are freely available for download at https://doi.org/10.15131/shef.data.17061509.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001650",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001650"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001650"
        },
        {
            "title": "Understanding geological reports based on knowledge graphs using a deep learning approach",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "Understanding geological reports based on knowledge graphs using a deep learning approach"
            },
            "summary": "<p><span><big>Understanding geological reports based on knowledge graphs using a deep learning approach</big></span><br /></p><p><span><small><i>Bin Wang, Liang Wu, Zhong Xie, Qinjun Qiu, ... Liufeng Tao</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105229</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Geological reports aid in understanding exploration by providing valuable information on rock formation ,evolution and the geological environment in which deposits formed. Querying and extracting the critical information from these enormous historical geological report data helps in understanding the exploration risks in different geological settings. However, large amounts of unstructured text data occur in geological reports; therefore, it is challenging to obtain valuable information from them without performing information extraction and processing. This study proposed an automated method for extracting information from geological reports through triple extraction, then automatically constructs a geological knowledge graph from the extracted entities and relations. Simultaneously, due to the lack of samples, this study used multiple geological reports to construct a corpus of jointly extracted geological entities and relations. The proposed model reached an F1-score of 90.05% in the experimental results on the constructed corpus. Finally, a knowledge graph was constructed based on the extracted results to demonstrate the application value of the proposed method. The results showed that the structured information helps better represent the content of the source report and matches well with the geological domain knowledge. The proposed method can quickly and robustly convert textual data into a structured form that is convenient for reasoning and querying geological entities and relations.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>Understanding geological reports based on knowledge graphs using a deep learning approach</big></span><br /></p><p><span><small><i>Bin Wang, Liang Wu, Zhong Xie, Qinjun Qiu, ... Liufeng Tao</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105229</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>Geological reports aid in understanding exploration by providing valuable information on rock formation ,evolution and the geological environment in which deposits formed. Querying and extracting the critical information from these enormous historical geological report data helps in understanding the exploration risks in different geological settings. However, large amounts of unstructured text data occur in geological reports; therefore, it is challenging to obtain valuable information from them without performing information extraction and processing. This study proposed an automated method for extracting information from geological reports through triple extraction, then automatically constructs a geological knowledge graph from the extracted entities and relations. Simultaneously, due to the lack of samples, this study used multiple geological reports to construct a corpus of jointly extracted geological entities and relations. The proposed model reached an F1-score of 90.05% in the experimental results on the constructed corpus. Finally, a knowledge graph was constructed based on the extracted results to demonstrate the application value of the proposed method. The results showed that the structured information helps better represent the content of the source report and matches well with the geological domain knowledge. The proposed method can quickly and robustly convert textual data into a structured form that is convenient for reasoning and querying geological entities and relations.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001789",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001789"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001789"
        },
        {
            "title": "A high-resolution panchromatic-multispectral satellite image fusion method assisted with building segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "A high-resolution panchromatic-multispectral satellite image fusion method assisted with building segmentation"
            },
            "summary": "<p><span><big>A high-resolution panchromatic-multispectral satellite image fusion method assisted with building segmentation</big></span><br /></p><p><span><small><i>Fang Gao, Yihui Li, Peng Zhang, Yuwei Zhai, ... Yuan An</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105219</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>The main difficulty of panchromatic-multispectral image fusion is to balance the quality of spatial information and the spectral fidelity. Most of the practical fusion methods determine the optimal parameters based on the spatial and spectral characteristics of all original panchromatic and multispectral bands. However, for built-up and non-built-up areas (like cropland, forest) in one image, there may be large differences in their spatial and spectral characteristics, so their fused results are not optimal respectively with same parameters. To address above issues, this paper presents a high-resolution satellite image fusion method assisted with building segmentation. First, the proposed approach computes the average gradient and Gaussian filtering parameters of built-up and non-built-up areas separately according to the building segmentation results, on the basis of smoothing filter-based intensity modulation (SFIM). Then the intermediate data of two types of areas are computed in parallel and they are composited to obtain the final fused image, weighted by the pixel-wise \u201cbuilding factors\u201d derived from the building segmentation results. Moreover, to better simulate the spatial characteristics of the multispectral image, we perform the \u201cgradient simulation\u201d operation to extract the gradient values in the multispectral image. Experimental results on Jilin-1 satellite images show that the proposed method provides competitive performance in spatial resolution, multispectral fidelity and quantity of information, as compared to the state-of-the-art methods in mainstream commercial software.</span><br /></p>",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "value": "<p><span><big>A high-resolution panchromatic-multispectral satellite image fusion method assisted with building segmentation</big></span><br /></p><p><span><small><i>Fang Gao, Yihui Li, Peng Zhang, Yuwei Zhai, ... Yuan An</i></small></span><br /><span><small><i>https://doi.org/10.1016/j.cageo.2022.105219</i></small></span><br /><span><small><i>Volume 168</i></small></span><br /></p><p><span>The main difficulty of panchromatic-multispectral image fusion is to balance the quality of spatial information and the spectral fidelity. Most of the practical fusion methods determine the optimal parameters based on the spatial and spectral characteristics of all original panchromatic and multispectral bands. However, for built-up and non-built-up areas (like cropland, forest) in one image, there may be large differences in their spatial and spectral characteristics, so their fused results are not optimal respectively with same parameters. To address above issues, this paper presents a high-resolution satellite image fusion method assisted with building segmentation. First, the proposed approach computes the average gradient and Gaussian filtering parameters of built-up and non-built-up areas separately according to the building segmentation results, on the basis of smoothing filter-based intensity modulation (SFIM). Then the intermediate data of two types of areas are computed in parallel and they are composited to obtain the final fused image, weighted by the pixel-wise \u201cbuilding factors\u201d derived from the building segmentation results. Moreover, to better simulate the spatial characteristics of the multispectral image, we perform the \u201cgradient simulation\u201d operation to extract the gradient values in the multispectral image. Experimental results on Jilin-1 satellite images show that the proposed method provides competitive performance in spatial resolution, multispectral fidelity and quantity of information, as compared to the state-of-the-art methods in mainstream commercial software.</span><br /></p>"
            },
            "id": "https://www.sciencedirect.com/science/article/pii/S0098300422001686",
            "guidislink": false,
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://www.sciencedirect.com/science/article/pii/S0098300422001686"
                }
            ],
            "link": "https://www.sciencedirect.com/science/article/pii/S0098300422001686"
        }
    ],
    "feed": {
        "title": "Computers & Geosciences",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
            "value": "Computers & Geosciences"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/journal/computers-and-geosciences"
            },
            {
                "href": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
                "rel": "self",
                "type": "application/rss+xml"
            }
        ],
        "link": "https://www.sciencedirect.com/journal/computers-and-geosciences",
        "subtitle": "Computers & Geosciences - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)",
        "subtitle_detail": {
            "type": "text/html",
            "language": null,
            "base": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
            "value": "Computers & Geosciences - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)"
        },
        "generator_detail": {
            "name": "RSSHub"
        },
        "generator": "RSSHub",
        "publisher": "i@diygod.me (DIYgod)",
        "publisher_detail": {
            "name": "DIYgod",
            "email": "i@diygod.me"
        },
        "language": "zh-cn",
        "updated": "Mon, 19 Sep 2022 16:06:31 GMT",
        "updated_parsed": [
            2022,
            9,
            19,
            16,
            6,
            31,
            0,
            262,
            0
        ],
        "ttl": "120"
    },
    "headers": {
        "date": "Mon, 19 Sep 2022 16:06:32 GMT",
        "content-type": "application/xml; charset=utf-8",
        "transfer-encoding": "chunked",
        "connection": "close",
        "vary": "Accept-Encoding",
        "access-control-allow-methods": "GET",
        "access-control-allow-origin": "rsshub.app",
        "cache-control": "public, max-age=7200",
        "last-modified": "Mon, 19 Sep 2022 16:06:31 GMT",
        "rsshub-node": "rss3",
        "x-content-type-options": "nosniff",
        "content-encoding": "gzip",
        "cf-cache-status": "HIT",
        "age": "1",
        "report-to": "{\"endpoints\":[{\"url\":\"https:\\/\\/a.nel.cloudflare.com\\/report\\/v3?s=1F5cLCYwW%2B%2FJfv%2BuXEN8BFTSHDvEgjJkiqPUsNfEygym6dP9KMyIllno6X2mbh33e0wbPB23Vv%2Byuh68NOBMST2jMHl%2B0KQgqLQPw8W4lybHHzT5p7BCboj6qSk%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}",
        "nel": "{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}",
        "server": "cloudflare",
        "cf-ray": "74d391b22ea48cf4-KIX"
    },
    "updated": "Mon, 19 Sep 2022 16:06:31 GMT",
    "updated_parsed": [
        2022,
        9,
        19,
        16,
        6,
        31,
        0,
        262,
        0
    ],
    "href": "https://rsshub.app/elsevier/computers-and-geosciences/latest",
    "status": 200,
    "encoding": "utf-8",
    "version": "rss20",
    "namespaces": {
        "": "http://www.w3.org/2005/Atom"
    }
}